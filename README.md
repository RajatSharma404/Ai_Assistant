# ğŸ¤– YourDaddy AI Assistant

<div align="center">

![Version](https://img.shields.io/badge/version-4.0.0-blue)
![Python](https://img.shields.io/badge/python-3.8+-green)
![License](https://img.shields.io/badge/license-MIT-orange)
![Platform](https://img.shields.io/badge/platform-Windows-lightgrey)

**A sophisticated AI-powered personal assistant featuring voice recognition, smart automation, multilingual support, and real-time AI responses powered by Google Gemini and OpenAI.**

[Features](#-key-features) â€¢ [Quick Start](#-quick-start-2-minutes) â€¢ [Installation](#-installation) â€¢ [Configuration](#-configuration) â€¢ [Documentation](#-documentation)

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Key Features](#-key-features)
- [Quick Start](#-quick-start-2-minutes)
- [Architecture](#-architecture)
- [Installation](#-detailed-installation)
- [Configuration](#-configuration)
- [Usage](#-usage)
- [Project Structure](#-project-structure)
- [API Integration](#-api-integrations)
- [Testing](#-testing)
- [Troubleshooting](#-troubleshooting)
- [Contributing](#-contributing)

---

## ğŸŒŸ Overview

**YourDaddy AI Assistant** is a comprehensive, voice-activated AI assistant that combines the power of **Google Gemini 2.0**, **OpenAI GPT**, advanced speech recognition, and intelligent automation to create a seamless personal assistant experience. Built with Python and modern web technologies, it offers multilingual support, multimodal capabilities (text, voice, vision), and extensive system integration.

### ğŸ¯ What Makes This Special

- ğŸ§  **Real-Time AI**: Intelligent responses using Google Gemini 2.0 Pro and OpenAI GPT-3.5/4
- ğŸ¤ **Voice Control**: Google Assistant-quality voice recognition with wake word detection
- ğŸŒ **Multilingual**: Support for English, Hindi, Hinglish, and multiple Indian languages
- ğŸ‘ï¸ **Vision AI**: Image analysis, OCR, and visual understanding
- ğŸ”„ **Smart Automation**: Windows app control, file operations, and task scheduling
- ğŸµ **Media Integration**: Spotify and YouTube Music control with voice commands
- ğŸŒ **Modern Web UI**: React + TypeScript interface with real-time WebSocket updates
- ğŸ”’ **Secure**: PIN-based authentication and encrypted API key management
- ğŸ“š **Learning System**: Adaptive learning with feedback loop and pattern recognition
- ğŸš« **Offline Capable**: Core features work without internet using Vosk and local models

---

## âœ¨ Key Features

### ğŸ¤– AI & Intelligence
- **Conversational AI**: Context-aware conversations with memory persistence
- **Google Gemini 2.0**: Latest multimodal AI models with vision support
- **OpenAI GPT Integration**: GPT-3.5 Turbo and GPT-4 support
- **Advanced Memory System**: Long-term context retention and relationship mapping
- **Adaptive Learning**: Pattern recognition and personalized responses
- **Knowledge Graphs**: Intelligent associations and context understanding
- **Feedback Learning**: User feedback integration for continuous improvement

### ğŸ™ï¸ Voice & Speech
- **Wake Word Detection**: "Hey Daddy", "OK Daddy" activation with local processing
- **Advanced Speech Recognition**: 
  - OpenAI Whisper API (online, highest accuracy)
  - Google Cloud Speech-to-Text
  - Vosk offline recognition (English & Hindi)
  - Browser-based Web Speech API
- **Neural Text-to-Speech**:
  - Microsoft Edge-TTS (natural neural voices)
  - Google Cloud TTS
  - Coqui TTS (offline fallback)
  - pyttsx3 (system voices)
- **Multilingual Support**: English, Hindi, Hinglish, Spanish, French, and more
- **Continuous Listening Mode**: Always-on voice detection with smart activation
- **Voice Activity Detection**: Advanced VAD with spectral feature analysis
- **Speaker Verification**: Voice profile management for secure access

### ğŸ–¥ï¸ System Integration & Automation
- **Smart App Discovery**: Automatic detection of 500+ installed Windows applications
- **Application Control**: Launch, close, and manage any Windows application
- **File Operations**: Create, move, copy, search, organize files and folders
- **Taskbar Detection**: Real-time window and application monitoring
- **System Control**: Volume, brightness, power management
- **Automation Tools**: Scheduled tasks, batch operations, system optimization

### ğŸ“… Productivity & Communication
- **Google Calendar Integration**: Event creation, reminders, scheduling
- **Email Automation**: Send, read, and manage emails via voice or text
- **Task Scheduling**: APScheduler-based automation with cron-like syntax
- **Document OCR**: Extract text from images and PDFs using Tesseract
- **Web Scraping**: Intelligent data extraction from websites
- **News & Weather**: Real-time news updates and weather forecasts
- **Stock & Crypto Prices**: Financial data monitoring

### ğŸµ Media & Entertainment
- **Spotify Integration**: 
  - Play, pause, skip, control playback
  - Create and manage playlists
  - Search songs, artists, albums
  - Get music recommendations
- **YouTube Music**: Search and play music videos
- **Music Downloader**: yt-dlp integration for audio/video downloads
- **Media Player Control**: System-wide media control

### ğŸŒ Modern Web Interface
- **React + TypeScript Frontend**: Modern, responsive UI built with Vite
- **Real-Time Communication**: WebSocket support for live updates
- **Flask Backend**: RESTful API with Flask-SocketIO
- **Mobile-Friendly**: Responsive design works on all devices
- **Dark/Light Themes**: Customizable appearance
- **Voice Web Commands**: Browser-based voice interaction
- **Live Status Updates**: Real-time system and AI status monitoring

### ğŸ‘ï¸ Multimodal & Vision
- **Image Analysis**: Visual understanding using Gemini Vision API
- **Video Processing**: Frame extraction and multi-frame analysis
- **Screen Capture Analysis**: Screenshot understanding and OCR
- **Object Detection**: Identify objects, faces, and scenes
- **Document Understanding**: Analyze document structure and content
- **Batch Processing**: Process multiple images/documents simultaneously

### ğŸ”’ Security & Privacy
- **PIN-Based Authentication**: Secure access control with configurable PIN
- **Encrypted Credentials**: Secure storage of API keys and tokens
- **Environment Variables**: Secure configuration management
- **Rate Limiting**: API request throttling and protection
- **JWT Tokens**: Secure session management
- **Local Processing**: Offline modes protect privacy

---

## ğŸš€ Quick Start (2 Minutes)

### Step 1: Install Dependencies
```bash
# Clone the repository
git clone <repository-url>
cd assitant

# Install Python dependencies
pip install -r requirements.txt
```

### Step 2: Setup API Keys (Free - 1 Minute)
```bash
# Run the quick setup wizard
python quick_ai_setup.py

# Get FREE Gemini API key:
# 1. Visit: https://aistudio.google.com/app/apikey
# 2. Sign in with Google account
# 3. Click "Create API Key"
# 4. Copy and paste when prompted
```

### Step 3: Start the Assistant
```bash
# Start with web interface (recommended)
python main.py

# Or use specific interface
python main.py --interface web --port 8000
python main.py --interface cli
```

### Step 4: Access & Test
```
ğŸŒ Web Interface: http://localhost:8000
ğŸ¤ Test Voice: "Hey Daddy, what's the weather today?"
ğŸ’¬ Test Chat: "Explain quantum computing"
```

**Expected**: Intelligent AI responses (not templates!)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     User Interfaces                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Web UI   â”‚  â”‚ Voice UI â”‚  â”‚ CLI      â”‚  â”‚ Desktop  â”‚   â”‚
â”‚  â”‚ (React)  â”‚  â”‚ (Speech) â”‚  â”‚ (Python) â”‚  â”‚ GUI (Tk) â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚             â”‚             â”‚             â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      Flask Backend (Port 8000)      â”‚
         â”‚    WebSocket + REST API Server       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚         Core AI System              â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
         â”‚  â”‚   Conversational AI        â”‚     â”‚
         â”‚  â”‚   - Context Management     â”‚     â”‚
         â”‚  â”‚   - Multi-turn Dialog      â”‚     â”‚
         â”‚  â”‚   - Memory System          â”‚     â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚          â”‚                  â”‚          â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚ AI/LLM   â”‚ â”‚ Voice  â”‚ â”‚  Automation   â”‚ â”‚ Integr â”‚
â”‚          â”‚ â”‚        â”‚ â”‚               â”‚ â”‚ -ationsâ”‚
â”‚ â€¢Gemini  â”‚ â”‚ â€¢ASR   â”‚ â”‚ â€¢App Control  â”‚ â”‚ â€¢Googleâ”‚
â”‚ â€¢OpenAI  â”‚ â”‚ â€¢TTS   â”‚ â”‚ â€¢File Ops     â”‚ â”‚ â€¢Spotifyâ”‚
â”‚ â€¢Memory  â”‚ â”‚ â€¢Wake  â”‚ â”‚ â€¢System Cmds  â”‚ â”‚ â€¢Email â”‚
â”‚ â€¢Learn   â”‚ â”‚ â€¢VAD   â”‚ â”‚ â€¢Scheduling   â”‚ â”‚ â€¢Web   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Detailed Installation

### Prerequisites
- **Python**: 3.8 or higher
- **OS**: Windows 10/11 (primary), Linux/Mac (experimental)
- **RAM**: 4GB minimum, 8GB recommended
- **Storage**: 2GB for dependencies and models

### Complete Installation Steps

#### 1. Clone Repository
```bash
git clone <repository-url>
cd assitant
```

#### 2. Create Virtual Environment (Recommended)
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

#### 3. Install Dependencies
```bash
# Install all requirements
pip install -r requirements.txt

# For development (includes testing tools)
pip install -r requirements.txt pytest pytest-cov black flake8
```

#### 4. Install Vosk Models (For Offline Voice)
```bash
# Download English model
python -c "from ai_assistant.voice import download_vosk_model; download_vosk_model('en')"

# Download Hindi model
python -c "from ai_assistant.voice import download_vosk_model; download_vosk_model('hi')"
```

#### 5. Install System Dependencies (Windows)
```bash
# Install Tesseract OCR (for document processing)
# Download from: https://github.com/UB-Mannheim/tesseract/wiki
# Add to PATH: C:\Program Files\Tesseract-OCR

# PyAudio (for microphone access)
pip install pipwin
pipwin install pyaudio
```

#### 6. Setup Configuration
```bash
# Run setup wizard
python quick_ai_setup.py

# Or manually create config files
cp config/app_integration.env.example config/app_integration.env
cp config/multimodal_config.json.example config/multimodal_config.json
```

#### 7. Setup API Keys

**Option A: Using Setup Wizard (Recommended)**
```bash
python quick_ai_setup.py
```

**Option B: Manual Setup**
Create `api_keys.json`:
```json
{
    "GEMINI_API_KEY": "your-gemini-api-key",
    "OPENAI_API_KEY": "your-openai-api-key",
    "SPOTIFY_CLIENT_ID": "your-spotify-client-id",
    "SPOTIFY_CLIENT_SECRET": "your-spotify-client-secret"
}
```

#### 8. Verify Installation
```bash
# Check dependencies
python check_dependencies.py

# Test AI integration
python test_ai_quick.py

# Test voice recognition
python test_import_core.py
```

---

## ğŸ”§ Configuration

### API Keys Configuration

#### Required Keys
1. **Gemini API** (Free - Recommended)
   - Get it: https://aistudio.google.com/app/apikey
   - Free tier: 60 requests/minute
   - Required for: AI conversations, vision analysis

2. **OpenAI API** (Optional - Paid)
   - Get it: https://platform.openai.com/api-keys
   - Cost: ~$0.002 per conversation (GPT-3.5)
   - Required for: OpenAI GPT models, Whisper API

#### Optional Keys
3. **Spotify API** (Free)
   - Get it: https://developer.spotify.com/dashboard
   - Required for: Music control features

4. **Google Cloud** (Free tier available)
   - Services: Calendar, Gmail, Speech-to-Text
   - Setup: https://console.cloud.google.com

### Configuration Files

#### 1. `api_keys.json` (Recommended)
```json
{
    "GEMINI_API_KEY": "AIza...",
    "OPENAI_API_KEY": "sk-...",
    "SPOTIFY_CLIENT_ID": "your-client-id",
    "SPOTIFY_CLIENT_SECRET": "your-client-secret",
    "GOOGLE_CLOUD_KEY_PATH": "path/to/credentials.json"
}
```

#### 2. `config/user_settings.json`
```json
{
    "language": "en",
    "voice_enabled": true,
    "wake_word": "hey daddy",
    "tts_engine": "edge-tts",
    "theme": "dark"
}
```

#### 3. `config/multimodal_config.json`
```json
{
    "vision_enabled": true,
    "max_image_size": 4096,
    "ocr_enabled": true,
    "video_processing": false
}
```

#### 4. Environment Variables (Alternative)
```bash
# Windows
set GEMINI_API_KEY=your-key-here
set OPENAI_API_KEY=your-key-here

# Linux/Mac
export GEMINI_API_KEY=your-key-here
export OPENAI_API_KEY=your-key-here
```

### Security Settings

#### Setup PIN Authentication
```bash
# First time setup
python setup_pin.py

# Or during startup
python main.py --setup-pin

# Skip for development (not recommended)
python main.py --skip-auth
```

---

## ğŸ® Usage

### Starting the Assistant

#### Web Interface (Recommended)
```bash
# Default (port 8000)
python main.py

# Custom port
python main.py --port 5000

# With verbose logging
python main.py --verbose

# Access at: http://localhost:8000
```

#### Command Line Interface
```bash
python main.py --interface cli
```

#### Desktop GUI
```bash
python main.py --interface desktop
```

### Using Voice Commands

#### Wake Word Activation
```
Say: "Hey Daddy" or "OK Daddy"
Wait for: Activation sound/beep
Then say: Your command
```

#### Example Voice Commands
```
"Hey Daddy, what's the weather today?"
"Open Chrome and search for Python tutorials"
"Play some relaxing music on Spotify"
"Create a meeting for tomorrow at 3 PM"
"Send an email to john@example.com"
"What's in this image?" (with image upload)
"Translate 'Hello' to Hindi"
"Set a reminder for 5 PM"
```

### Using Text Commands

#### Web Interface
1. Open http://localhost:8000
2. Type your query in the chat box
3. Press Enter or click Send

#### CLI Interface
```bash
$ python main.py --interface cli
> What's the capital of France?
> Open notepad
> Play music by Coldplay
> quit  # To exit
```

### Advanced Usage

#### Automation Scripts
```bash
# Schedule automated tasks
python scripts/setup/setup_automation.py

# Run batch file operations
python -c "from ai_assistant.file_ops import organize_files_by_type; organize_files_by_type('~/Downloads')"
```

#### API Endpoints

**Health Check**
```bash
curl http://localhost:8000/api/health
```

**Send Message**
```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello!", "user_id": "user123"}'
```

**Get Features**
```bash
curl http://localhost:8000/api/features
```

**Voice Recognition**
```bash
curl -X POST http://localhost:8000/api/voice/recognize \
  -F "audio=@recording.wav"
```

---

## ğŸ“ Project Structure

```
assitant/
â”œâ”€â”€ main.py                          # Main entry point with interface selection
â”œâ”€â”€ pyproject.toml                   # Project metadata and configuration
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ pytest.ini                       # Testing configuration
â”œâ”€â”€ api_keys.json                    # API keys (gitignored)
â”‚
â”œâ”€â”€ ai_assistant/                    # Main package
â”‚   â”œâ”€â”€ __init__.py                  # Package initialization
â”‚   â”‚
â”‚   â”œâ”€â”€ ai/                          # AI & Machine Learning
â”‚   â”‚   â”œâ”€â”€ conversational_ai.py     # Main conversation engine
â”‚   â”‚   â”œâ”€â”€ llm_provider.py          # LLM abstraction layer
â”‚   â”‚   â”œâ”€â”€ memory.py                # Context and memory management
â”‚   â”‚   â”œâ”€â”€ advanced_feedback_learning.py  # Adaptive learning system
â”‚   â”‚   â””â”€â”€ knowledge_graph.py       # Relationship mapping
â”‚   â”‚
â”‚   â”œâ”€â”€ voice/                       # Voice Processing
â”‚   â”‚   â”œâ”€â”€ advanced_speech_recognizer.py  # ASR (Whisper, Google, Vosk)
â”‚   â”‚   â”œâ”€â”€ neural_voice_engine.py   # TTS (Edge-TTS, Google, Coqui)
â”‚   â”‚   â”œâ”€â”€ wake_word_detector.py    # Wake word detection
â”‚   â”‚   â”œâ”€â”€ voice_activity_detection.py   # VAD with spectral analysis
â”‚   â”‚   â”œâ”€â”€ speaker_verification.py  # Voice profile management
â”‚   â”‚   â””â”€â”€ advanced_voice.py        # Unified voice interface
â”‚   â”‚
â”‚   â”œâ”€â”€ integrations/                # External Services
â”‚   â”‚   â”œâ”€â”€ google_calendar.py       # Calendar integration
â”‚   â”‚   â”œâ”€â”€ email_handler.py         # Email automation
â”‚   â”‚   â”œâ”€â”€ spotify_integration.py   # Spotify control
â”‚   â”‚   â”œâ”€â”€ youtube_music.py         # YouTube Music
â”‚   â”‚   â”œâ”€â”€ web_search_integration.py # Web search
â”‚   â”‚   â””â”€â”€ google_assistant_voice_integration.py  # Voice integration
â”‚   â”‚
â”‚   â”œâ”€â”€ automation/                  # System Automation
â”‚   â”‚   â”œâ”€â”€ smart_automation.py      # Intelligent automation
â”‚   â”‚   â”œâ”€â”€ app_discovery.py         # Application detection
â”‚   â”‚   â”œâ”€â”€ windows_control.py       # Windows automation
â”‚   â”‚   â””â”€â”€ task_scheduler.py        # Task scheduling
â”‚   â”‚
â”‚   â”œâ”€â”€ interfaces/                  # User Interfaces
â”‚   â”‚   â”œâ”€â”€ modern_interfaces.py     # Interface management
â”‚   â”‚   â”œâ”€â”€ websocket_handlers.py    # WebSocket communication
â”‚   â”‚   â””â”€â”€ rest_api.py              # REST API endpoints
â”‚   â”‚
â”‚   â”œâ”€â”€ apps/                        # Application Entry Points
â”‚   â”‚   â”œâ”€â”€ modern_web_backend.py    # Flask web server
â”‚   â”‚   â”œâ”€â”€ app.py                   # CLI application
â”‚   â”‚   â””â”€â”€ yourdaddy_app.py         # Desktop GUI
â”‚   â”‚
â”‚   â”œâ”€â”€ modules/                     # Utility Modules
â”‚   â”‚   â”œâ”€â”€ conversational_ai.py     # Enhanced conversation
â”‚   â”‚   â”œâ”€â”€ multilingual.py          # Language support
â”‚   â”‚   â”œâ”€â”€ multimodal.py            # Multimodal processing
â”‚   â”‚   â”œâ”€â”€ youtube_ops.py           # YouTube operations
â”‚   â”‚   â””â”€â”€ modern_interfaces.py     # Interface utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                        # Core Functionality
â”‚   â”‚   â”œâ”€â”€ core.py                  # Core system
â”‚   â”‚   â”œâ”€â”€ system.py                # System utilities
â”‚   â”‚   â””â”€â”€ config.py                # Configuration management
â”‚   â”‚
â”‚   â”œâ”€â”€ auth/                        # Authentication
â”‚   â”‚   â”œâ”€â”€ pin_auth.py              # PIN authentication
â”‚   â”‚   â””â”€â”€ security.py              # Security utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ database/                    # Data Persistence
â”‚   â”‚   â”œâ”€â”€ conversation_db.py       # Conversation storage
â”‚   â”‚   â”œâ”€â”€ feedback_db.py           # Feedback data
â”‚   â”‚   â””â”€â”€ memory_db.py             # Memory management
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                       # Utilities
â”‚   â”‚   â”œâ”€â”€ logging_config.py        # Logging setup
â”‚   â”‚   â”œâ”€â”€ file_utils.py            # File operations
â”‚   â”‚   â””â”€â”€ validators.py            # Input validation
â”‚   â”‚
â”‚   â””â”€â”€ services/                    # Background Services
â”‚       â”œâ”€â”€ scheduler_service.py     # Task scheduling
â”‚       â””â”€â”€ monitoring_service.py    # System monitoring
â”‚
â”œâ”€â”€ config/                          # Configuration Files
â”‚   â”œâ”€â”€ app_integration.env          # App configuration
â”‚   â”œâ”€â”€ multimodal_config.json       # Multimodal settings
â”‚   â”œâ”€â”€ user_settings.json           # User preferences
â”‚   â””â”€â”€ discovered_apps.json         # Discovered applications
â”‚
â”œâ”€â”€ scripts/                         # Utility Scripts
â”‚   â”œâ”€â”€ setup/                       # Setup scripts
â”‚   â”‚   â”œâ”€â”€ setup_google_assistant_voice.py
â”‚   â”‚   â”œâ”€â”€ setup_automation.py
â”‚   â”‚   â””â”€â”€ install_dependencies.py
â”‚   â”œâ”€â”€ analysis/                    # Analysis tools
â”‚   â””â”€â”€ debug/                       # Debugging utilities
â”‚
â”œâ”€â”€ tests/                           # Test Suite
â”‚   â”œâ”€â”€ test_ai_quick.py             # Quick AI tests
â”‚   â”œâ”€â”€ test_advanced_learning.py    # Learning system tests
â”‚   â”œâ”€â”€ test_all_27_systems.py       # Integration tests
â”‚   â”œâ”€â”€ test_voice_recognition.py    # Voice tests
â”‚   â””â”€â”€ test_api_endpoints.py        # API tests
â”‚
â”œâ”€â”€ project/                         # Frontend Project
â”‚   â”œâ”€â”€ src/                         # React TypeScript source
â”‚   â”œâ”€â”€ public/                      # Static assets
â”‚   â”œâ”€â”€ package.json                 # npm dependencies
â”‚   â””â”€â”€ vite.config.ts               # Vite configuration
â”‚
â”œâ”€â”€ docs/                            # Documentation
â”‚   â”œâ”€â”€ README.md                    # Comprehensive docs
â”‚   â”œâ”€â”€ API_REFERENCE_COMPLETE.md    # API documentation
â”‚   â”œâ”€â”€ CHANGELOG.md                 # Version history
â”‚   â””â”€â”€ INTEGRATION_GUIDE.md         # Integration guide
â”‚
â”œâ”€â”€ data/                            # Runtime Data
â”œâ”€â”€ logs/                            # Application Logs
â”œâ”€â”€ static/                          # Static Web Assets
â”œâ”€â”€ templates/                       # HTML Templates
â”œâ”€â”€ user_data/                       # User-Specific Data
â”œâ”€â”€ offline_cache/                   # Offline Model Cache
â””â”€â”€ model/                           # ML Models

```

---

## ğŸ”Œ API Integrations

### 1. Google Gemini AI
- **Purpose**: Primary AI conversational engine
- **Features**: Text generation, vision analysis, multimodal understanding
- **Setup**: Get free API key from https://aistudio.google.com/app/apikey
- **Usage**: 60 requests/minute free tier

### 2. OpenAI
- **Purpose**: Alternative LLM, Whisper speech recognition
- **Models**: GPT-3.5-Turbo, GPT-4, Whisper API
- **Setup**: https://platform.openai.com/api-keys
- **Cost**: Pay-per-use (~$0.002/conversation)

### 3. Spotify
- **Purpose**: Music playback and playlist management
- **Setup**: https://developer.spotify.com/dashboard
- **Scopes**: streaming, playlist-modify, user-library-read

### 4. Google Cloud Services
- **Speech-to-Text**: High-accuracy voice recognition
- **Text-to-Speech**: Natural voice synthesis
- **Calendar API**: Event management
- **Gmail API**: Email automation
- **Setup**: https://console.cloud.google.com

### 5. Vosk (Offline)
- **Purpose**: Offline speech recognition
- **Languages**: English, Hindi, 20+ others
- **Setup**: Automatic model download
- **No API Key Required**

---

## ğŸ§ª Testing

### Run All Tests
```bash
# Run all tests
pytest

# With coverage report
pytest --cov=ai_assistant --cov-report=html

# Specific test file
pytest tests/test_ai_quick.py

# Verbose output
pytest -v
```

### Test Specific Components

#### AI Integration
```bash
python test_ai_quick.py
python test_real_ai.py
```

#### Voice Recognition
```bash
python test_import_core.py
python ai_assistant/voice/test_voice_recognition.py
```

#### All 27 Systems
```bash
python test_all_27_systems.py
```

#### Web Backend
```bash
python test_api_endpoints.py
```

### Manual Testing

#### Test AI Response
```python
from ai_assistant.ai import get_ai_response

response = get_ai_response("What is quantum computing?")
print(response)
```

#### Test Voice Recognition
```python
from ai_assistant.voice import recognize_speech

text, confidence = recognize_speech()
print(f"You said: {text} (confidence: {confidence})")
```

#### Test Automation
```python
from ai_assistant.automation import open_application

open_application("Chrome")
```

---

## ğŸ”§ Troubleshooting

### Common Issues

#### 1. Import Errors
```bash
# Problem: ModuleNotFoundError
# Solution: Ensure virtual environment is activated and dependencies installed
pip install -r requirements.txt
```

#### 2. API Key Not Working
```bash
# Check AI status
python check_ai_status.py

# Verify keys are loaded
python -c "from ai_assistant.ai import check_api_keys; check_api_keys()"
```

#### 3. Voice Recognition Not Working
```bash
# Check microphone permissions (Windows)
# Settings > Privacy > Microphone > Allow apps

# Test PyAudio installation
python -c "import pyaudio; print('PyAudio OK')"

# Download Vosk models
python -c "from ai_assistant.voice import download_vosk_model; download_vosk_model('en')"
```

#### 4. Web Interface Not Loading
```bash
# Check port availability
netstat -ano | findstr :8000

# Try different port
python main.py --port 5000

# Check firewall settings
```

#### 5. Tesseract OCR Not Found
```bash
# Windows: Download and install from
# https://github.com/UB-Mannheim/tesseract/wiki

# Add to PATH or set environment variable
set TESSERACT_CMD=C:\Program Files\Tesseract-OCR\tesseract.exe
```

### Debug Mode
```bash
# Enable verbose logging
python main.py --verbose

# Check logs
cat logs/assistant.log

# Debug specific module
python debug_launcher.py
```

### Getting Help
1. Check [docs/](docs/) directory for detailed documentation
2. Review [TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md)
3. Check [logs/](logs/) for error messages
4. Run diagnostic tools: `python check_dependencies.py`

---

## ğŸ¤ Contributing

We welcome contributions! See [CONTRIBUTING.md](docs/CONTRIBUTING.md) for guidelines.

### Development Setup
```bash
# Fork and clone repository
git clone https://github.com/yourusername/assitant.git

# Create feature branch
git checkout -b feature/amazing-feature

# Install development dependencies
pip install -r requirements.txt pytest black flake8

# Make changes and test
pytest
black ai_assistant/
flake8 ai_assistant/

# Commit and push
git commit -m "Add amazing feature"
git push origin feature/amazing-feature
```

---

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE.txt](docs/LICENSE.txt) for details.

---

## ğŸ™ Acknowledgments

- **Google Gemini**: Advanced AI capabilities
- **OpenAI**: GPT and Whisper models
- **Vosk**: Offline speech recognition
- **Edge-TTS**: Neural text-to-speech
- **Flask & React**: Web framework and UI
- **All Contributors**: Thank you for your contributions!

---

## ğŸ“ Support

- **Documentation**: [docs/README.md](docs/README.md)
- **API Reference**: [docs/API_REFERENCE_COMPLETE.md](docs/API_REFERENCE_COMPLETE.md)
- **Quick Reference**: [QUICK_REFERENCE.md](QUICK_REFERENCE.md)
- **Integration Guide**: [INTEGRATION_GUIDE.md](INTEGRATION_GUIDE.md)

---

<div align="center">

**Made with â¤ï¸ by the YourDaddy AI Team**

â­ Star us on GitHub if you find this helpful!

</div>